# Deep Web Crawler - Gu√≠a de Uso

Crawler para la deep web que utiliza Tor para navegar de forma an√≥nima y PostgreSQL para almacenar los resultados. El programa rastrea enlaces `.onion` de forma autom√°tica y organizada.

## üìã Requisitos Previos

Antes de ejecutar el programa, necesitas tener instalado y configurado lo siguiente:

### 1. Python 3.x
- Aseg√∫rate de tener Python 3 instalado en tu sistema.
- Puedes verificar la versi√≥n con: `python --version`

### 2. Tor Expert Bundle
- **Descarga**: [Tor Expert Bundle](https://www.torproject.org/download/tor/)
- **Instalaci√≥n**: Extrae el archivo en una carpeta de tu elecci√≥n.
- **Ejecuci√≥n**: Debes iniciar Tor antes de ejecutar el crawler.
  - En Windows: Ejecuta `tor.exe` desde la carpeta extra√≠da.
  - El puerto por defecto es `9050` (configurado en el script).

### 3. PostgreSQL
- **Descarga e instalaci√≥n**: [PostgreSQL Download](https://www.postgresql.org/download/)
- Durante la instalaci√≥n, recuerda la contrase√±a que configures para el usuario `postgres`.
- Aseg√∫rate de que el servicio de PostgreSQL est√© corriendo.

## üîß Instalaci√≥n

### Paso 1: Instalar dependencias de Python

Abre una terminal en la carpeta del proyecto y ejecuta:

```bash
pip install -r requirements.txt
```

Esto instalar√° las siguientes librer√≠as:
- `requests==2.31.0` - Para realizar peticiones HTTP
- `beautifulsoup4==4.12.2` - Para parsear HTML
- `psycopg2-binary==2.9.9` - Para conectar con PostgreSQL

### Paso 2: Crear la base de datos

Abre PostgreSQL (pgAdmin o l√≠nea de comandos) y crea la base de datos:

```sql
CREATE DATABASE deepweb_crawler;
```

El script crear√° autom√°ticamente las tablas necesarias al ejecutarse por primera vez.

## ‚öôÔ∏è Configuraci√≥n

Antes de ejecutar el programa, **DEBES modificar** las siguientes variables en el archivo del script:

### 1. Configuraci√≥n de PostgreSQL (L√≠neas 27-31)

```python
DB_HOST = "localhost"        # Cambiar si PostgreSQL est√° en otro servidor
DB_NAME = "deepweb_crawler"  # Nombre de la base de datos (debe existir)
DB_USER = "postgres"         # Usuario de PostgreSQL
DB_PASS = ""                 # ‚ö†Ô∏è OBLIGATORIO: Poner tu contrase√±a aqu√≠
DB_PORT = "5432"             # Puerto de PostgreSQL (por defecto 5432)
```

**‚ö†Ô∏è IMPORTANTE**: Debes poner tu contrase√±a de PostgreSQL en `DB_PASS`.

### 2. Configuraci√≥n de Rutas (L√≠nea 34)

```python
BASE_DIR = r"C:\Users\TuUser\Desktop\Carpeta"
```

**‚ö†Ô∏è DEBES CAMBIAR** `TuUser` por tu nombre de usuario de Windows, o usar otra ruta v√°lida.

Ejemplo:
```python
BASE_DIR = r"C:\Users\Juan\Desktop\DeepWebLinks"
```

### 3. Configuraci√≥n de Tor (L√≠neas 16-21)

Por defecto est√° configurado para el puerto est√°ndar de Tor:

```python
TOR_PORT = 9050  # Solo cambiar si Tor usa otro puerto
```

Si tu Tor est√° configurado en otro puerto, cambia este valor.

### 4. Configuraci√≥n Opcional

#### URL Semilla (L√≠nea 43)
```python
SEED_URL = "http://wkkrcvje42625v7g77maufsgvqbu7eh7tgfvwzqrarqptfktqiaa6ayd.onion/darkweb-search-engines-v3/hidden-wiki"
```
Esta es la URL inicial desde donde comenzar√° el crawler. Puedes cambiarla por otra URL `.onion` si lo deseas.

#### Timeout de Peticiones (L√≠nea 46)
```python
REQUEST_TIMEOUT = 20  # Segundos de espera antes de considerar timeout
```

#### L√≠mite de Enlaces por Dominio (L√≠nea 47)
```python
MAX_LINKS_PER_DOMAIN = 15  # M√°ximo de enlaces por dominio antes de descartarlo
```

## üöÄ Ejecuci√≥n

### Paso 1: Iniciar Tor

Antes de ejecutar el script, aseg√∫rate de que Tor est√© corriendo:
- Ejecuta `tor.exe` desde la carpeta de Tor Expert Bundle.
- Espera a que se conecte (ver√°s mensajes en la consola).

### Paso 2: Verificar PostgreSQL

Aseg√∫rate de que el servicio de PostgreSQL est√© activo:
- En Windows: Verifica en "Servicios" que PostgreSQL est√© corriendo.
- O intenta conectarte con pgAdmin o psql.

### Paso 3: Ejecutar el Script

```bash
python "### Para poder iniciar el programa neces.py"
```

O si renombras el archivo a algo m√°s simple (ej: `crawler.py`):
```bash
python crawler.py
```

### Paso 4: Seleccionar Modo

Al iniciar, el programa te mostrar√° un men√∫:

```
========================================
   SELECTOR DE MODO CRAWLER (POSTGRES)
========================================
1. Modo Normal (Cola: X | Completados: Y)
2. Modo Reintentos (Cola 404: Z enlaces)
========================================
```

- **Modo Normal (1)**: Procesa URLs nuevas de la cola principal.
- **Modo Reintentos (2)**: Reintenta URLs que dieron error 404 anteriormente.

## üìä Funcionamiento

### Inicializaci√≥n
1. El script crea autom√°ticamente las tablas en PostgreSQL si no existen:
   - `queue`: Cola principal de URLs pendientes
   - `crawled_pages`: P√°ginas ya visitadas con sus t√≠tulos y c√≥digos de estado
   - `retry_queue`: URLs que dieron error 404 para reintentar
   - `domain_stats`: Estad√≠sticas de cu√°ntos enlaces se han encontrado por dominio

2. Si es la primera ejecuci√≥n, inserta la URL semilla en la cola.

### Proceso de Crawling
1. Toma una URL de la cola (seg√∫n el modo seleccionado).
2. Realiza una petici√≥n HTTP a trav√©s de Tor.
3. Si la respuesta es exitosa (200):
   - Extrae el t√≠tulo de la p√°gina.
   - Guarda la informaci√≥n en PostgreSQL.
   - Guarda una copia en el archivo TXT.
   - Busca todos los enlaces `.onion` en la p√°gina.
   - Agrega los nuevos enlaces a la cola (respetando el l√≠mite por dominio).
4. Si hay errores (404, timeout, etc.):
   - Registra el error en la base de datos.
   - En modo Normal: agrega URLs 404 a la cola de reintentos.
   - En modo Reintentos: rota la URL al final de la cola para intentar m√°s tarde.

### Almacenamiento de Datos

#### Base de Datos PostgreSQL
- **`crawled_pages`**: Contiene todas las URLs visitadas con t√≠tulo y c√≥digo de estado.
- **`queue`**: URLs pendientes de procesar.
- **`retry_queue`**: URLs con error 404 para reintentar.
- **`domain_stats`**: Control de l√≠mites por dominio.

#### Archivo de Texto
- Se guarda en: `{BASE_DIR}/onion_links.txt`
- Formato:
  ```
  T√çTULO: Nombre de la p√°gina
  URL: http://ejemplo.onion/ruta
  --------------------------------------------------
  ```

## üõë Detener el Programa

Para detener el crawler de forma segura:
- Presiona `Ctrl + C` en la terminal.
- El programa guardar√° el estado y cerrar√° las conexiones correctamente.

## ‚ö†Ô∏è Notas Importantes

1. **Tor debe estar corriendo**: El programa fallar√° si Tor no est√° activo en el puerto 9050.
2. **PostgreSQL debe estar activo**: Verifica que el servicio est√© corriendo antes de ejecutar.
3. **Velocidad**: El script espera 2 segundos entre cada petici√≥n para no saturar.
4. **L√≠mites**: Cada dominio solo puede tener m√°ximo 15 enlaces en la cola para evitar saturaci√≥n.
5. **Primera ejecuci√≥n**: La primera vez puede tardar m√°s mientras se conecta a trav√©s de Tor.

## üîç Soluci√≥n de Problemas

### Error: "Error conectando a Postgres"
- Verifica que PostgreSQL est√© corriendo.
- Revisa que la contrase√±a en `DB_PASS` sea correcta.
- Confirma que la base de datos `deepweb_crawler` existe.

### Error: "ConnectionError" o "Timeout"
- Verifica que Tor est√© corriendo.
- Espera unos segundos y vuelve a intentar (Tor puede estar iniciando).
- Revisa que el puerto 9050 est√© disponible.

### Error: "No se pudo crear el directorio"
- Verifica que la ruta en `BASE_DIR` sea v√°lida.
- Aseg√∫rate de tener permisos de escritura en esa ubicaci√≥n.

### El programa no encuentra enlaces
- Algunas p√°ginas pueden no tener enlaces `.onion`.
- La URL semilla puede no estar disponible.
- Intenta cambiar la `SEED_URL` por otra.

## üìù Estructura de Tablas

### Tabla: `queue`
```sql
id (SERIAL PRIMARY KEY)
url (TEXT UNIQUE)
```

### Tabla: `crawled_pages`
```sql
id (SERIAL PRIMARY KEY)
url (TEXT UNIQUE)
title (TEXT)
status_code (INTEGER)
```

### Tabla: `retry_queue`
```sql
id (SERIAL PRIMARY KEY)
url (TEXT UNIQUE)
```

### Tabla: `domain_stats`
```sql
domain (TEXT PRIMARY KEY)
count (INTEGER DEFAULT 0)
```

## üìå Resumen de Cambios Necesarios

Antes de ejecutar, **DEBES modificar**:

1. ‚úÖ **L√≠nea 30**: `DB_PASS = ""` ‚Üí Poner tu contrase√±a de PostgreSQL
2. ‚úÖ **L√≠nea 34**: `BASE_DIR = r"C:\Users\TuUser\Desktop\Carpeta"` ‚Üí Cambiar `TuUser` por tu usuario

Opcional:
- L√≠nea 43: Cambiar `SEED_URL` si quieres empezar desde otra p√°gina
- L√≠nea 46: Ajustar `REQUEST_TIMEOUT` si es necesario
- L√≠nea 47: Cambiar `MAX_LINKS_PER_DOMAIN` para ajustar l√≠mites

## üìÑ Licencia

Este proyecto es de uso educativo. √ösalo de forma responsable y respetando las leyes de tu pa√≠s.

